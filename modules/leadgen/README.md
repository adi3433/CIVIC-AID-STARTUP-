# AUTOGENERATED BY CLAUDE: date=2026-02-05

# LeadGen Module

**Owner:** Lestlin  
**Port:** 5003

## Overview

This module analyzes case text using RAG (Retrieval Augmented Generation) and provides structured recommendations for next steps.

## Quick Start

```bash
# From project root
python -m modules.leadgen.leadgen_stub
```

The module is now integrated into the main application.

### Access
- URL: `http://localhost:5002/leadgen.html`
- API Endpoint: `/api/leadgen/analyze` (Hosted on port 5002)

## API Endpoints

### POST /leadgen/analyze

Analyze case text and generate recommendations.

**Request:**
```json
{
  "case_text": "Vehicle theft reported near MG Road. Witness saw blue sedan.",
  "case_id": "CASE-2026-001"
}
```

**Response:**
```json
{
  "case_id": "CASE-2026-001",
  "recommendations": [
    {"step": "Check CCTV footage from nearby cameras", "confidence": 0.95},
    {"step": "Interview witness for vehicle description", "confidence": 0.90},
    {"step": "Alert nearby patrol units", "confidence": 0.85}
  ]
}
```

## Testing

```bash
pytest tests/ -v
```

## TODO: Production Integration

1. Implement RAG pipeline with LangChain
   - Set up document vectorization
   - Configure retrieval strategy
   
2. Connect to OpenAI/local LLM for generation

3. Add case database integration

4. Implement confidence score calibration

5. Add PDF metadata extraction
